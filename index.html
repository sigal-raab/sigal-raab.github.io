

<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link type="text/css" rel="stylesheet" href="style.css"/>
	<title>Sigal Raab</title>
</head>


<body>
<!-- menu  -->
<!--div id=menu>
<p><a href=#about>About</a> ||| <a href=#publications>Publications</a> </p>
</div-->

<h1 id="about">Sigal Raab</h1>
<div id="container">
  <img class="container__image" src="./home_images/sigal_profile_pic_cropped2.png">

 <div class="container__text">
	 I am a Ph.D candidate at the Tel-Aviv University, under the supervision of <a href="https://danielcohenor.com/">Prof. Daniel Cohen-Or</a>.
     <br/><br>

	 I am interested in machine learning, computer graphics, and computer vision.<br>
     My particular interest lies in generative AI, specifically in the realm of human motion and animation.
     <br/><br>
     Email: sigal.raab@gmail.com  <br/>
 </div>
</div>


<h1 id="publications">Publications</h1>

 <!--br/><br/--><br>
 <img class="paper_image" src="./home_images/MoDi_from_Danny.gif">
 <div class="paper_text">
 <strong>MoDi: Unconditional Motion Synthesis from Diverse Data</strong> <br/>
<strong>Sigal Raab</strong>, Inbal Leibovitch, Peizhuo Li, Kfir Aberman, Olga Sorkine-Hornung, Daniel Cohen-Or<br/>
<i>CVPR 2023</i> <br/>
 <a href="https://arxiv.org/abs/2206.08010"><code>Paper</code></a>
 <a href="https://sigal-raab.github.io/MoDi.html"><code>Project</code></a>
 <a href="https://www.youtube.com/watch?v=O1sVzwrsNUg"><code>Video</code></a>
 <a href="https://github.com/sigal-raab/MoDi"><code>Code</code></a>
 </div>

 <br/><br/><br>
 <img class="paper_image" src="./home_images/MDM_from_Danny.jpeg">
 <div class="paper_text">
 <strong>Human Motion Diffusion Model</strong> <br/>
Guy Tevet, <strong>Sigal Raab</strong>, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, Amit H. Bermano<br/>
<i>ICLR 2023 (oral)</i> <br/>
 <a href="https://arxiv.org/abs/2209.14916"><code>Paper</code></a>
 <a href="https://guytevet.github.io/mdm-page"><code>Project</code></a>
 <a href="https://www.youtube.com/watch?v=rVkIDj5wgjs&t=1s"><code>Video</code></a>
 <a href="https://github.com/GuyTevet/motion-diffusion-model"><code>Code</code></a>
 <a href="https://replicate.com/arielreplicate/motion_diffusion_model"><code>Demo</code></a>
 </div>

 <br/><br/><br>
 <img class="paper_image" src="./home_images/FLEX_from_Danny.png">
 <div class="paper_text">
 <strong>FLEX: Extrinsic Parameters-free Multi-view 3D Human Motion Reconstruction</strong> <br/>
Brian Gordon*, <strong>Sigal Raab*</strong>, Guy Azov, Raja Giryes, Daniel Cohen-Or<br/>
<i>ECCV 2022</i> <br/>
 <a href="https://arxiv.org/abs/2105.01937"><code>Paper</code></a>
 <a href="https://www.youtube.com/watch?v=hXc97BDJJTg"><code>Video</code></a>
 <a href="https://github.com/BrianG13/FLEX"><code>Code</code></a>
 </div>

 <br/><br/><br>
</body>
</html>
